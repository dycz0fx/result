 benchmarks to run Reduce 
#------------------------------------------------------------
#    Intel (R) MPI Benchmarks 4.0 Update 1, MPI-1 part    
#------------------------------------------------------------
# Date                  : Wed Aug 24 16:52:06 2016
# Machine               : x86_64
# System                : Linux
# Release               : 4.5.4-1.el6.elrepo.x86_64
# Version               : #1 SMP Thu May 12 15:15:24 EDT 2016
# MPI Version           : 3.1
# MPI Thread Environment: 

# New default behavior from Version 3.2 on:

# the number of iterations per message size is cut down 
# dynamically when a certain run time (per message size sample) 
# is expected to be exceeded. Time limit is defined by variable 
# "SECS_PER_SAMPLE" (=> IMB_settings.h) 
# or through the flag => -time 
  


# Calling sequence was: 

# /home/dycz0fx/program/imb/src/IMB-MPI1 Reduce -msglen /home/dycz0fx/Lengths -npmin 8 -iter 1000
#                                       

# Message lengths were user defined
#
# MPI_Datatype                   :   MPI_BYTE 
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM  
#
#

# List of Benchmarks to run:

# Reduce
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline
Base reduce pipeline

#----------------------------------------------------------------
# Benchmarking Reduce 
# #processes = 8 
#----------------------------------------------------------------
       #bytes #repetitions  t_min[usec]  t_max[usec]  t_avg[usec]
        65536          888       824.62       825.53       825.09
       131072          800      1578.69      1580.58      1579.66
       262144          664      2292.65      2295.60      2294.24
       524288          496      2805.42      2809.15      2807.53
      1048576          328      4248.89      4255.21      4252.46
      2097152          200      7295.23      7306.78      7301.67
      4194304          104     13030.45     13051.82     13042.45


# All processes entering MPI_Finalize

